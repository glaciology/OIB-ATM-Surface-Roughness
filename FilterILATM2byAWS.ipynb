{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to filter processed ILATM2 data within 5km radius of PROMICE and GC-NET on-ice weather stations. \n",
    "\n",
    "### - Shapefiles for weather station locations and coastline taken from QGreenland. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and dependencies \n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline_gpd = gpd.read_file(\"./greenlandCoastline.shp\") # Load coastline .shp \n",
    "GCNET_gdf = gpd.read_file(\"./WxStations/GCNETSites.shp\") # Load weather station .shps \n",
    "PROMICE_gdf = gpd.read_file(\"./WxStations/PROMICESites.shp\")\n",
    "\n",
    "GCNET_gdf = GCNET_gdf.to_crs(coastline_gpd.crs) # Set weather stations to coastline CRS \n",
    "PROMICE_gdf = PROMICE_gdf.to_crs(coastline_gpd.crs)\n",
    "\n",
    "GCNET_gdf[\"buffered_5km\"] = GCNET_gdf.buffer(5000) # Buffer station locations with a 5 km radius \n",
    "PROMICE_gdf[\"buffered_5km\"] = PROMICE_gdf.buffer(5000)\n",
    "\n",
    "weather_stations = gpd.GeoDataFrame(pd.concat([GCNET_gdf, PROMICE_gdf], ignore_index=True), crs=coastline_gpd.crs) # Concatenate \n",
    " \n",
    "main_folder_path = \"./weather_stations/\"   \n",
    "output_folder_path = \"./weather_stations_5km/\"\n",
    "\n",
    "os.makedirs(output_folder_path, exist_ok=True) # Create output directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each buffered .csv\n",
    "\n",
    "for csv_file in os.listdir(main_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        csv_file_path = os.path.join(main_folder_path, csv_file)\n",
    "        print(f\"Processing file: {csv_file_path}\")\n",
    "        df = pd.read_csv(csv_file_path) # Read .csvs \n",
    "        df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "        df = df.rename(str.strip, axis='columns')\n",
    "        tmp_gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['Longitude(deg)'], df['Latitude(deg)']), crs='EPSG:4326') # Convert to gdfs \n",
    "        tmp_gdf = tmp_gdf.to_crs(coastline_gpd.crs) # Convert gdf CRS to coastline CRS \n",
    "        clipped_data = [] \n",
    "        for i in range(len(weather_stations)):\n",
    "            clipped_gdf = gpd.clip(tmp_gdf, weather_stations.loc[i, \"buffered_5km\"]) # Clip the data within the 5km buffers \n",
    "            if not clipped_gdf.empty:\n",
    "                clipped_data.append(clipped_gdf)\n",
    "        if clipped_data: # Save clipped data \n",
    "            out = pd.concat(clipped_data).drop(columns='geometry') \n",
    "            output_file_path = os.path.join(output_folder_path, csv_file.replace('.csv', '_5km_buffered.csv'))\n",
    "            out.to_csv(output_file_path, index=False)\n",
    "            print(f\"File saved: {output_file_path}\")\n",
    "        else: \n",
    "            print(f\"No data after clipped for file: {csv_file}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
